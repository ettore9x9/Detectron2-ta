{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ettore9x9/Detectron2-ta/blob/main/DetectTraversable_Detectron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ2c4CPimBKb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install Detectron2\n",
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "!python -m pip install labelme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d288Z2mF5dC"
      },
      "outputs": [],
      "source": [
        "# Import and print versions\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLWaQGJXm0bB"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import scipy.io as sio\n",
        "import json\n",
        "from skimage import measure\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ovVMKnVnRNz"
      },
      "outputs": [],
      "source": [
        "# download datasets\n",
        "os.makedirs(\"./zipData\", exist_ok=True)\n",
        "!wget -P ./zipData https://mikeprocopio.com/downloads/lagr/labeled_lagr_data_640x480_DS1A.ZIP\n",
        "!wget -P ./zipData https://mikeprocopio.com/downloads/lagr/labeled_lagr_data_640x480_DS1B.ZIP\n",
        "!wget -P ./zipData https://mikeprocopio.com/downloads/lagr/labeled_lagr_data_640x480_DS2A.ZIP\n",
        "!wget -P ./zipData https://mikeprocopio.com/downloads/lagr/labeled_lagr_data_640x480_DS2B.ZIP\n",
        "!wget -P ./zipData https://mikeprocopio.com/downloads/lagr/labeled_lagr_data_640x480_DS3A.ZIP\n",
        "!wget -P ./zipData https://mikeprocopio.com/downloads/lagr/labeled_lagr_data_640x480_DS3B.ZIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE0g5k6c5Z79"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from PIL import Image\n",
        "\n",
        "def convert_mat_to_png(matfile, outputfile):\n",
        "    mat_contents = sio.loadmat(matfile)\n",
        "    img_rgb = mat_contents['im_rgb']\n",
        "    out = Image.fromarray(img_rgb)\n",
        "    out.save(outputfile)\n",
        "\n",
        "def convert_mat_to_mask(matfile, outputfile):\n",
        "    mat = sio.loadmat(matfile)\n",
        "    mask = mat['manual_human_labeling_mask']\n",
        "    out = Image.fromarray(mask.astype(np.uint8), mode='L')\n",
        "    out.save(outputfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1vBtLz8cLZ5"
      },
      "outputs": [],
      "source": [
        "# decompress data\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "datasets_paths = ['/content/zipData/labeled_lagr_data_640x480_DS1A.ZIP',\n",
        "                  '/content/zipData/labeled_lagr_data_640x480_DS1B.ZIP',\n",
        "                  '/content/zipData/labeled_lagr_data_640x480_DS2A.ZIP',\n",
        "                  '/content/zipData/labeled_lagr_data_640x480_DS2B.ZIP',\n",
        "                  '/content/zipData/labeled_lagr_data_640x480_DS3A.ZIP',\n",
        "                  '/content/zipData/labeled_lagr_data_640x480_DS3B.ZIP'\n",
        "                  ]\n",
        "\n",
        "extract_path = '/content/data'\n",
        "train_path   = '/content/train'\n",
        "val_path     = '/content/val'\n",
        "test_path    = '/content/test'\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "os.makedirs(train_path,   exist_ok=True)\n",
        "os.makedirs(val_path,     exist_ok=True)\n",
        "os.makedirs(test_path,    exist_ok=True)\n",
        "\n",
        "train_rgb_path  = '/content/train/rgb'\n",
        "train_mask_path = '/content/train/mask'\n",
        "val_rgb_path    = '/content/val/rgb'\n",
        "val_mask_path   = '/content/val/mask'\n",
        "test_rgb_path   = '/content/test/rgb'\n",
        "test_mask_path  = '/content/test/mask'\n",
        "\n",
        "os.makedirs(train_rgb_path,  exist_ok=True)\n",
        "os.makedirs(train_mask_path, exist_ok=True)\n",
        "os.makedirs(val_rgb_path,    exist_ok=True)\n",
        "os.makedirs(val_mask_path,   exist_ok=True)\n",
        "os.makedirs(test_rgb_path,   exist_ok=True)\n",
        "os.makedirs(test_mask_path,  exist_ok=True)\n",
        "\n",
        "train_ratio = 0.8\n",
        "val_ratio   = 0.1\n",
        "i = 0\n",
        "\n",
        "for zip_file_path in datasets_paths:\n",
        "  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_path)\n",
        "\n",
        "  files = os.listdir(extract_path)\n",
        "  random.shuffle(files)\n",
        "\n",
        "  split_train_index = int(len(files) * train_ratio)\n",
        "  split_val_index   = int(len(files) * val_ratio) + split_train_index\n",
        "  train_files = files[:split_train_index]\n",
        "  val_files   = files[split_train_index:split_val_index]\n",
        "  test_files  = files[split_val_index:]\n",
        "\n",
        "  for filename in train_files:\n",
        "      src_path      = os.path.join(extract_path,    filename)\n",
        "      dst_path_rgb  = os.path.join(train_rgb_path,  \"frame\"+str(i)+\".png\")\n",
        "      dst_path_mask = os.path.join(train_mask_path, \"frame\"+str(i)+\".png\")\n",
        "      i = i+1\n",
        "      convert_mat_to_png(src_path, dst_path_rgb)\n",
        "      convert_mat_to_mask(src_path, dst_path_mask)\n",
        "\n",
        "  for filename in val_files:\n",
        "      src_path      = os.path.join(extract_path,  filename)\n",
        "      dst_path_rgb  = os.path.join(val_rgb_path,  \"frame\"+str(i)+\".png\")\n",
        "      dst_path_mask = os.path.join(val_mask_path, \"frame\"+str(i)+\".png\")\n",
        "      i = i+1\n",
        "      convert_mat_to_png(src_path, dst_path_rgb)\n",
        "      convert_mat_to_mask(src_path, dst_path_mask)\n",
        "\n",
        "  for filename in test_files:\n",
        "      src_path      = os.path.join(extract_path,   filename)\n",
        "      dst_path_rgb  = os.path.join(test_rgb_path,  \"frame\"+str(i)+\".png\")\n",
        "      dst_path_mask = os.path.join(test_mask_path, \"frame\"+str(i)+\".png\")\n",
        "      i = i+1\n",
        "      convert_mat_to_png(src_path, dst_path_rgb)\n",
        "      convert_mat_to_mask(src_path, dst_path_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxB0jaU7eMrn"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_data_dicts(directory):\n",
        "    dataset_dicts = []\n",
        "    rgb_dir  = directory + \"/rgb\"\n",
        "    mask_dir = directory + \"/mask\"\n",
        "    for filename in [file for file in os.listdir(rgb_dir)]:\n",
        "        rgb_file  = os.path.join(rgb_dir, filename)\n",
        "        mask_file = os.path.join(mask_dir, filename)\n",
        "\n",
        "        record = {}\n",
        "        record[\"file_name\"] = rgb_file\n",
        "        record[\"height\"] = 640\n",
        "        record[\"width\"] = 480\n",
        "        record[\"image_id\"] = re.findall(r'\\d+', filename)[-1]\n",
        "        record[\"sem_seg_file_name\"] = mask_file\n",
        "\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvJHz-N_xkCM"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/'\n",
        "\n",
        "for d in [\"train\", \"val\", \"test\"]:\n",
        "    DatasetCatalog.register(\n",
        "        \"category_\" + d,\n",
        "        lambda d=d: get_data_dicts(data_path+d)\n",
        "    )\n",
        "\n",
        "stuff_classes = [\"traversable\", \"obstacle\"]\n",
        "\n",
        "MetadataCatalog.get(\"category_train\").set(stuff_classes=stuff_classes)\n",
        "MetadataCatalog.get(\"category_train\").set(ignore_label=2)\n",
        "MetadataCatalog.get(\"category_val\").set(stuff_classes=stuff_classes)\n",
        "MetadataCatalog.get(\"category_val\").set(ignore_label=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSga6Fhpjg1z"
      },
      "outputs": [],
      "source": [
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
        "import detectron2.data.transforms as T\n",
        "from detectron2.data.dataset_mapper import DatasetMapper\n",
        "from detectron2.data import build_detection_train_loader\n",
        "from detectron2.evaluation import SemSegEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHcKlLtM0h0A"
      },
      "outputs": [],
      "source": [
        "transform_list = [\n",
        "    T.RandomBrightness(0.8, 1.2),\n",
        "    T.RandomContrast(0.8, 1.2),\n",
        "    T.RandomSaturation(0.8, 1.2),\n",
        "    T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
        "]\n",
        "\n",
        "class MyTrainer(DefaultTrainer):\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "        \n",
        "            return SemSegEvaluator(\n",
        "                    dataset_name,\n",
        "                    distributed=True,\n",
        "                    output_dir=output_folder,\n",
        "                    )\n",
        "\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        mapper = DatasetMapper(cfg, is_train=True, augmentations=transform_list)\n",
        "        return build_detection_train_loader(cfg, mapper=mapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aUbl9fWyEHE"
      },
      "outputs": [],
      "source": [
        "# Semantic segmentation settings\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"Base-RCNN-FPN.yaml\"))\n",
        "\n",
        "cfg.DATASETS.TRAIN = (\"category_train\",)\n",
        "cfg.DATASETS.TEST = (\"category_test\",)\n",
        "cfg.MODEL.META_ARCHITECTURE = \"SemanticSegmentor\"\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
        "cfg.MODEL.RESNETS.DEPTH = 50\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (480)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = (640)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupMultiStepLR\"\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.SOLVER.BASE_LR = 0.02\n",
        "cfg.SOLVER.MOMENTUM = 0.9\n",
        "cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
        "cfg.SOLVER.GAMMA = 0.1\n",
        "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000\n",
        "cfg.SOLVER.WARMUP_ITERS = 300\n",
        "cfg.SOLVER.IMS_PER_BATCH = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN10cDLvyGJs"
      },
      "outputs": [],
      "source": [
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = MyTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syfy1TfzJSOO"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxqUwI6syLGy"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrjrtI-qyNPP"
      },
      "outputs": [],
      "source": [
        "eval_dataset = get_data_dicts(data_path+'val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOdzuxgLyREL"
      },
      "outputs": [],
      "source": [
        "# Show images with semantic segmentation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for d in random.sample(eval_dataset, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(img)\n",
        "    v = Visualizer(img[:, :, ::-1],\n",
        "                   scale=0.8,\n",
        "                   metadata=MetadataCatalog.get(\"category_val\"),\n",
        "                   instance_mode=ColorMode.SEGMENTATION\n",
        "    )\n",
        "    v = v.draw_sem_seg((outputs[\"sem_seg\"].argmax(dim=0)).to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # Transpose the image for display pourposes\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1].transpose(1, 0, 2), cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!zip -r /content/out.zip /content/output\n",
        "files.download(\"/content/out.zip\")"
      ],
      "metadata": {
        "id": "dMjSWmKBTlRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}